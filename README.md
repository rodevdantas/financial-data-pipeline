# ðŸ“Š ETL Pipeline and Interactive Stock Dashboard

This project was developed with the goal of practicing and integrating knowledge in **data engineering**, **cloud automation**, and **interactive visualization**, creating an end-to-end solution for stock market analysis.

## Project Objective

- Build an automated ETL pipeline hosted in the cloud, which collects, transforms, and loads data daily.  
- Create a layered architecture (Bronze, Silver, Gold) for data organization.  
- Make the data available in a low-cost solution (Google Sheets).  
- Connect the processed data to an interactive dashboard in Looker Studio, providing insights into performance and volatility of major market companies.  
- Practice a full-stack data approach, combining data collection, processing, storage, and visualization in a single project.  

## Technologies Used

### ðŸ”¹ Google Cloud Platform (GCP)
- **Cloud Functions** â†’ serverless execution of Python code.  
- **Cloud Scheduler** â†’ schedule daily execution of the pipeline.  

### ðŸ”¹ Python
- **pandas** â†’ manipulation, cleaning, and transformation of tabular data.  
- **yfinance** â†’ extraction of stock market quotes and information.  
- **logging** â†’ monitoring and traceability of pipeline execution.  

### ðŸ”¹ Visualization and Storage
- **Google Sheets** â†’ storage of processed data, acting as a low-cost data lake.  
- **Looker Studio** â†’ creation of an interactive and dynamic dashboard.  

## Solution Architecture

The project follows a layered data architecture:

- **Bronze** â†’ raw data extracted from the Yahoo Finance API.  
- **Silver** â†’ cleaned, standardized, and enriched data.  
- **Gold** â†’ final table with consolidated metrics for analysis.  

**Pipeline flow**:  
`Cloud Scheduler â†’ Cloud Function (ETL in Python) â†’ Google Sheets â†’ Looker Studio`  

## How to Explore

You can simply explore the project by viewing the code or accessing the public links:  

- **Dashboard:** [Looker Studio Dashboard](https://lookerstudio.google.com/u/0/reporting/b1fd8ae3-8545-458c-b6e4-0d2d236d86e5/page/bAjWF)  
- **Processed Data:** [Google Sheets](https://docs.google.com/spreadsheets/d/1H779bzHVLrPaaHEuLEIRsJt1OdSXKBu02GmlhST2EjI/)  

To review the code:  
```
git clone https://github.com/your-username/financial-data-pipeline.git
cd financial-data-pipeline
```

The dashboard shows:  
- **Closing price** â†’ daily and consolidated values per stock.  
- **Total trading volume** â†’ total traded per asset.  
- **Average daily variation** â†’ a measure of volatility.  
- **Company comparison** â†’ trend charts and comparative bar charts.  

**Analyzed companies (tickers):**  
AAPL (Apple), MSFT (Microsoft), GOOGL (Google), AMZN (Amazon), TSLA (Tesla), META (Meta), NVDA (NVIDIA), BRK-B (Berkshire Hathaway), JPM (JPMorgan Chase), JNJ (Johnson & Johnson)

## Project Structure

ðŸ“‚ financial-data-pipeline/  
â”‚  
â”œâ”€â”€ main.py # ETL and execution in Cloud Functions  
â”œâ”€â”€ requirements.txt # List of dependencies  
â”œâ”€â”€ README.md # Project documentation  

## Skills

- **Data Engineering** â†’ ETL, layered modeling, best practices in Python.  
- **Cloud Computing** â†’ use of serverless services and automation with GCP.  
- **Data Analysis** â†’ volatility calculations, financial metrics, and indicators.  
- **Visualization** â†’ building an interactive dashboard in Looker Studio, applying Data Storytelling principles.  
- **End-to-end integration** â†’ automated pipeline combining extraction, transformation, storage, and visual presentation.  

## Notes

This project simulates a real market solution, focusing on **automation, scalability, and UI**.  
More than just extracting data, the goal was to **build a complete data journey**, from back-end to front-end.

